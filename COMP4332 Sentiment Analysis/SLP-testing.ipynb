{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, Dropout, BatchNormalization, Activation, Input, \\\n",
    "    Conv1D, MaxPool1D, Flatten, Concatenate, Add\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split_name='train', columns=['text', 'stars']):\n",
    "    try:\n",
    "        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'data_2021_spring/{split_name}.csv')\n",
    "        df = df.loc[:,columns]\n",
    "        print(\"succeed!\")\n",
    "        return df\n",
    "    except:\n",
    "        print(\"Failed, then try to \")\n",
    "        print(f\"select all columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'data_2021_spring/{split_name}.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [f, u, l, l] columns from the train split\n",
      "Failed, then try to \n",
      "select all columns from the train split\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train', columns='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "Preprocessing and feature engineering is important in machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(s):\n",
    "    \"\"\"\n",
    "    :param s: a string.\n",
    "    return a string with lower characters\n",
    "    Note that we allow the input to be nested string of a list.\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: 'text mining is to identify useful information.'\n",
    "    \"\"\"\n",
    "    if isinstance(s, list):\n",
    "        return [lower(t) for t in s]\n",
    "    if isinstance(s, str):\n",
    "        return s.lower()\n",
    "    else:\n",
    "        raise NotImplementedError(\"unknown datatype\")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    :param text: a doc with multiple sentences, type: str\n",
    "    return a word list, type: list\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "def stem(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of stemmed words, type: list\n",
    "    e.g.\n",
    "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    ### equivalent code\n",
    "    # results = list()\n",
    "    # for token in tokens:\n",
    "    #     results.append(ps.stem(token))\n",
    "    # return results\n",
    "\n",
    "    return [ps.stem(token) for token in tokens]\n",
    "\n",
    "def n_gram(tokens, n=1):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    :param n: the corresponding n-gram, type: int\n",
    "    return a list of n-gram tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.'], 2\n",
    "    Output: ['text mine', 'mine is', 'is to', 'to identifi', 'identifi use', 'use inform', 'inform .']\n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return tokens\n",
    "    else:\n",
    "        results = list()\n",
    "        for i in range(len(tokens)-n+1):\n",
    "            # tokens[i:i+n] will return a sublist from i th to i+n th (i+n th is not included)\n",
    "            results.append(\" \".join(tokens[i:i+n]))\n",
    "        return results\n",
    "\n",
    "def filter_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of filtered tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    ### equivalent code\n",
    "    # results = list()\n",
    "    # for token in tokens:\n",
    "    #     if token not in stopwords and not token.isnumeric():\n",
    "    #         results.append(token)\n",
    "    # return results\n",
    "\n",
    "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feats_dict(feats, min_freq=-1, max_freq=-1, max_size=-1):\n",
    "    \"\"\"\n",
    "    :param data: a list of features, type: list(list)\n",
    "    :param min_freq: the lowest fequency that the fequency of a feature smaller than it will be filtered out, type: int\n",
    "    :param max_freq: the highest fequency that the fequency of a feature larger than it will be filtered out, type: int\n",
    "    :param max_size: the max size of feature dict, type: int\n",
    "    return a feature dict that maps features to indices, sorted by frequencies\n",
    "    # Counter document: https://docs.python.org/3.6/library/collections.html#collections.Counter\n",
    "    \"\"\"\n",
    "    # count all features\n",
    "    feat_cnt = Counter(feats) # [\"text\", \"text\", \"mine\"] --> {\"text\": 2, \"mine\": 1}\n",
    "    if max_size > 0 and min_freq == -1 and max_freq == -1:\n",
    "        valid_feats = [f for f, cnt in feat_cnt.most_common(max_size)]\n",
    "    else:\n",
    "        valid_feats = list()\n",
    "        for f, cnt in feat_cnt.most_common():\n",
    "            if (min_freq == -1 or cnt >= min_freq) and \\\n",
    "                (max_freq == -1 or cnt <= max_freq):\n",
    "                valid_feats.append(f)\n",
    "    if max_size > 0 and len(valid_feats) > max_size:\n",
    "        valid_feats = valid_feats[:max_size]        \n",
    "    print(\"Size of features:\", len(valid_feats))\n",
    "    \n",
    "    # build a mapping from features to indices\n",
    "    feats_dict = dict(zip(valid_feats, range(len(valid_feats))))\n",
    "    return feats_dict\n",
    "\n",
    "def get_onehot_vector(feats, feats_dict):\n",
    "    \"\"\"\n",
    "    :param feats: a list of features, type: list\n",
    "    :param feats_dict: a dict from features to indices, type: dict\n",
    "    return a feature vector,\n",
    "    \"\"\"\n",
    "    # initialize the vector as all zeros\n",
    "    vector = np.zeros(len(feats_dict), dtype=np.float)\n",
    "    for f in feats:\n",
    "        # get the feature index, return -1 if the feature is not existed\n",
    "        f_idx = feats_dict.get(f, -1)\n",
    "        if f_idx != -1:\n",
    "            # set the corresponding element as 1\n",
    "            vector[f_idx] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [f, u, l, l] columns from the train split\n",
      "Failed, then try to \n",
      "select all columns from the train split\n",
      "select [f, u, l, l] columns from the valid split\n",
      "Failed, then try to \n",
      "select all columns from the valid split\n",
      "Size of features: 39838\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train', columns='full')\n",
    "valid_df = load_data('valid', columns='full')\n",
    "\n",
    "\n",
    "train_ids = train_df['review_id']\n",
    "train_texts = train_df['text']\n",
    "train_labels = train_df['stars']\n",
    "\n",
    "test_ids = valid_df['review_id']\n",
    "test_texts = valid_df['text']\n",
    "test_labels = valid_df['stars']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# extract features\n",
    "train_tokens = [tokenize(text) for text in train_texts]\n",
    "test_tokens = [tokenize(text) for text in test_texts]\n",
    "\n",
    "train_stemmed = [stem(tokens) for tokens in train_tokens]\n",
    "test_stemmed = [stem(tokens) for tokens in test_tokens]\n",
    "\n",
    "train_stemmed = [filter_stopwords(tokens) for tokens in train_stemmed]\n",
    "test_stemmed = [filter_stopwords(tokens) for tokens in test_stemmed]\n",
    "\n",
    "train_2_gram = [n_gram(tokens, 2) for tokens in train_stemmed]\n",
    "train_3_gram = [n_gram(tokens, 3) for tokens in train_stemmed]\n",
    "test_2_gram = [n_gram(tokens, 2) for tokens in test_stemmed]\n",
    "test_3_gram = [n_gram(tokens, 3) for tokens in test_stemmed]\n",
    "\n",
    "# build the feature list\n",
    "train_feats = list()\n",
    "for i in range(len(train_ids)):\n",
    "    train_feats.append(\n",
    "        train_stemmed[i] + train_2_gram[i] + train_3_gram[i])\n",
    "test_feats = list()\n",
    "for i in range(len(test_ids)):\n",
    "    test_feats.append(\n",
    "        test_stemmed[i] + test_2_gram[i] + test_3_gram[i])\n",
    "\n",
    "# build a mapping from features to indices\n",
    "feats_dict = get_feats_dict(\n",
    "    chain.from_iterable(train_feats),\n",
    "    min_freq=5)\n",
    "\n",
    "# build the feats_matrix\n",
    "# convert each example to a ont-hot vector, and then stack vectors as a matrix\n",
    "train_feats_matrix = np.vstack(\n",
    "    [get_onehot_vector(f, feats_dict) for f in train_feats])\n",
    "test_feats_matrix = np.vstack(\n",
    "    [get_onehot_vector(f, feats_dict) for f in test_feats])\n",
    "\n",
    "# convert labels to label_matrix\n",
    "num_classes = max(train_labels)\n",
    "# convert each label to a ont-hot vector, and then stack vectors as a matrix\n",
    "train_label_matrix = keras.utils.to_categorical(train_labels-1, num_classes=num_classes)\n",
    "test_label_matrix = keras.utils.to_categorical(test_labels-1, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmed feature size: 24119\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first, build a Counter for stemmed features, e.g., {\"text\": 2, \"mine\": 1}\n",
    "stemmed_feat_cnt = Counter()\n",
    "for feats in train_stemmed:\n",
    "    stemmed_feat_cnt.update(feats)\n",
    "print(\"stemmed feature size:\", len(stemmed_feat_cnt))\n",
    "\n",
    "# then, get the sorted features by the frequency\n",
    "stemmed_feat_keys = [f for f, cnt in stemmed_feat_cnt.most_common()]\n",
    "\n",
    "# draw linear lines and log lines for sorted features\n",
    "# set the figure size\n",
    "plt.figure(figsize=(10,4))\n",
    "# generate two subfigures and set current as the first one\n",
    "plt.subplot(1,2,1)\n",
    "# draw linear lines\n",
    "plt.plot(range(1, len(stemmed_feat_cnt)+1),\n",
    "         [stemmed_feat_cnt[f] for f in stemmed_feat_keys])\n",
    "# set labels\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Feature Frequency\")\n",
    "# set current as the second one\n",
    "plt.subplot(1,2,2)\n",
    "# draw log lines\n",
    "plt.loglog(range(1, len(stemmed_feat_cnt)+1),\n",
    "           [stemmed_feat_cnt[f] for f in stemmed_feat_keys],\n",
    "           basex=10, basey=10)\n",
    "# set labels\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Feature Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmed feature size: 24119\n",
      "2-gram feature size: 331339\n",
      "3-gram feature size: 688795\n"
     ]
    }
   ],
   "source": [
    "# build Counters for 2-gram features and 3-gram features\n",
    "bi_gram_feat_cnt = Counter()\n",
    "for feats in train_2_gram:\n",
    "    bi_gram_feat_cnt.update(feats)\n",
    "    \n",
    "tri_gram_feat_cnt = Counter()\n",
    "for feats in train_3_gram:\n",
    "    tri_gram_feat_cnt.update(feats)\n",
    "\n",
    "# then, get the sorted features by the frequency\n",
    "bi_gram_feat_keys = [f for f, cnt in bi_gram_feat_cnt.most_common()]\n",
    "tri_gram_feat_keys = [f for f,cnt in tri_gram_feat_cnt.most_common()]\n",
    "\n",
    "# draw linear lines and log lines for sorted features\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "# put the four linear lines together\n",
    "plt.plot(range(1, len(stemmed_feat_cnt)+1),\n",
    "         [stemmed_feat_cnt[f] for f in stemmed_feat_keys],\n",
    "         label=\"stemmed\")\n",
    "plt.plot(range(1, len(bi_gram_feat_cnt)+1),\n",
    "         [bi_gram_feat_cnt[f] for f in bi_gram_feat_keys],\n",
    "         label=\"2-gram\")\n",
    "plt.plot(range(1, len(tri_gram_feat_cnt)+1),\n",
    "         [tri_gram_feat_cnt[f] for f in tri_gram_feat_keys],\n",
    "         label=\"3-gram\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Feature Frequency\")\n",
    "# show the legend\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "# put the four log lines together\n",
    "plt.loglog(range(1, len(stemmed_feat_cnt)+1),\n",
    "         [stemmed_feat_cnt[f] for f in stemmed_feat_keys],\n",
    "           basex=10, basey=10, label=\"stemmed\")\n",
    "plt.loglog(range(1, len(bi_gram_feat_cnt)+1),\n",
    "         [bi_gram_feat_cnt[f] for f in bi_gram_feat_keys],\n",
    "           basex=10, basey=10, label=\"2-gram\")\n",
    "plt.loglog(range(1, len(tri_gram_feat_cnt)+1),\n",
    "         [tri_gram_feat_cnt[f] for f in tri_gram_feat_keys],\n",
    "           basex=10, basey=10, label=\"3-gram\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Feature Frequency\")\n",
    "# show the legend\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"stemmed feature size:\", len(stemmed_feat_cnt))\n",
    "print(\"2-gram feature size:\", len(bi_gram_feat_cnt))\n",
    "print(\"3-gram feature size:\", len(tri_gram_feat_cnt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmed features > 10: 4217\n",
      "2-gram features > 10: 9173\n",
      "3-gram features > 10: 2870\n"
     ]
    }
   ],
   "source": [
    "print(\"stemmed features > 10:\",\n",
    "      len([f for f, cnt in stemmed_feat_cnt.items() if cnt > 10]))\n",
    "print(\"2-gram features > 10:\",\n",
    "      len([f for f, cnt in bi_gram_feat_cnt.items() if cnt > 10]))\n",
    "print(\"3-gram features > 10:\",\n",
    "      len([f for f, cnt in tri_gram_feat_cnt.items() if cnt > 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmed features top 10: ['.', ',', 'I', 'wa', '!', 'thi', \"n't\", \"'s\", 'food', 'place']\n",
      "2-gram features top 10: ['. I', ', I', '! !', '. We', '. It', 'I wa', 'thi place', \"I 'm\", 'I would', \"I n't\"]\n",
      "3-gram features top 10: ['! ! !', '. It wa', \". It 's\", '. I wa', \". I 'm\", '. I would', \". I n't\", 'thi place .', ', I wa', \". I 've\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"stemmed features top 10:\",\n",
    "      stemmed_feat_keys[:10])\n",
    "print(\"2-gram features top 10:\",\n",
    "      bi_gram_feat_keys[:10])\n",
    "print(\"3-gram features top 10:\",\n",
    "      tri_gram_feat_keys[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_classifier(input_size, output_size,\n",
    "                     loss=\"categorical_crossentropy\",\n",
    "                     optimizer=\"SGD\",\n",
    "                     learning_rate=0.1,\n",
    "                     metric=\"accuracy\"):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # the projection layer\n",
    "    model.add(Dense(output_size,\n",
    "                    activation=\"softmax\",\n",
    "                    input_dim=input_size,\n",
    "                    bias_initializer=\"zeros\"))\n",
    "    \n",
    "    # set the loss, the optimizer, and the metric\n",
    "    if optimizer == \"SGD\":\n",
    "        optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    elif optimizer == \"RMSprop\":\n",
    "        optmizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Adam\":\n",
    "        optmizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Adadelta'\":\n",
    "        optmizer = keras.optimizers.Adadelta(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Adagrad\":\n",
    "        optmizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Adamax\":\n",
    "        optmizer = keras.optimizers.Adamax(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Nadam\":\n",
    "        optmizer = keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 189 candidates, totalling 378 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=SGD ..................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=SGD, score=0.563, total=   5.8s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.0s remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=SGD ..................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=SGD, score=0.558, total=   6.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   12.3s remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=RMSprop, score=0.585, total=   4.9s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.4s remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=RMSprop, score=0.584, total=   6.6s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   24.3s remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=Adagrad, score=0.485, total=   8.2s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   32.7s remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=Adagrad, score=0.464, total=   5.6s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   38.5s remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=Adadelta .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\", line 223, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\wrappers\\scikit_learn.py\", line 157, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-16-177f3648638c>\", line 2, in create_model\n",
      "    model = build_classifier(input_size=len(feats_dict), output_size=num_classes,optimizer=optimizer, learning_rate=lr)\n",
      "  File \"<ipython-input-13-ce77873a0733>\", line 37, in build_classifier\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   39.6s remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=Adadelta .............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   40.5s remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=Adam .................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=Adam, score=0.586, total=  10.1s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   50.9s remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=Adam .................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=Adam, score=0.584, total=   5.7s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   56.8s remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=Adamax ...............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=Adamax, score=0.563, total=   4.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=Adamax ...............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=Adamax, score=0.567, total=   8.5s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=Nadam ................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=Nadam, score=0.589, total=  10.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  1.3min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.01, optimizer=Nadam ................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.01, optimizer=Nadam, score=0.578, total=   9.7s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=SGD ...................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=SGD, score=0.573, total=   3.7s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=SGD ...................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=SGD, score=0.558, total=   3.8s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=RMSprop ...............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=RMSprop, score=0.586, total=   5.8s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=RMSprop ...............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=RMSprop, score=0.584, total=   5.5s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=Adagrad ...............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=Adagrad, score=0.499, total=   4.1s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=Adagrad ...............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=Adagrad, score=0.471, total=   7.9s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=Adadelta ..............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=Adadelta, score=nan, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=Adadelta ..............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=Adam ..................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=Adam, score=0.585, total=   3.9s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=Adam ..................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=Adam, score=0.584, total=   4.2s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  2.2min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=Adamax ................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=Adamax, score=0.564, total=   5.4s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=Adamax ................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=Adamax, score=0.566, total=   4.9s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=Nadam .................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=Nadam, score=0.586, total=  10.2s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.6min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.1, optimizer=Nadam .................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.1, optimizer=Nadam, score=0.584, total=   7.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  2.7min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=SGD ...................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=SGD, score=0.543, total=   5.1s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  2.8min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=SGD ...................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=SGD, score=0.479, total=   6.3s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.9min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=RMSprop ...............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=RMSprop, score=0.584, total=   5.6s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  3.0min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=RMSprop ...............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=RMSprop, score=0.582, total=  12.6s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  3.2min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=Adagrad ...............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=Adagrad, score=0.490, total=   5.4s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  3.3min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=Adagrad ...............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=Adagrad, score=0.467, total=   3.9s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=Adadelta ..............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=Adadelta, score=nan, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=Adadelta ..............\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=Adadelta, score=nan, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=Adam ..................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=Adam, score=0.586, total=   5.7s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  3.5min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=Adam ..................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=Adam, score=0.587, total=   5.9s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  3.6min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=Adamax ................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=Adamax, score=0.564, total=   5.7s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  3.7min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=Adamax ................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=Adamax, score=0.569, total=   8.9s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  3.8min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=Nadam .................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=Nadam, score=0.585, total=   5.6s\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:  3.9min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=2, lr=0.5, optimizer=Nadam .................\n",
      "[CV]  batch_size=5, epochs=2, lr=0.5, optimizer=Nadam, score=0.584, total=   5.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=SGD ..................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=SGD, score=0.576, total=   6.1s\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=SGD ..................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=SGD, score=0.574, total=   6.6s\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:  4.3min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=RMSprop, score=0.586, total=  11.5s\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  4.5min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=RMSprop, score=0.590, total=   7.4s\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=Adagrad, score=0.536, total=   6.2s\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:  4.7min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=Adagrad, score=0.513, total=   8.2s\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=Adadelta .............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=Adadelta, score=nan, total=   0.9s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=Adadelta .............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  4.9min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=Adam .................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=Adam, score=0.584, total=   8.1s\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:  5.0min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=Adam .................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=Adam, score=0.570, total=  10.5s\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:  5.2min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=Adamax ...............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=Adamax, score=0.581, total=   6.8s\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:  5.3min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=Adamax ...............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=Adamax, score=0.578, total=   7.0s\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  5.4min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=Nadam ................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=Nadam, score=0.586, total=  10.3s\n",
      "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:  5.6min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.01, optimizer=Nadam ................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.01, optimizer=Nadam, score=0.574, total=  11.1s\n",
      "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:  5.8min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=SGD ...................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=SGD, score=0.567, total=   7.2s\n",
      "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:  5.9min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=SGD ...................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=SGD, score=0.569, total=   7.9s\n",
      "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:  6.0min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=RMSprop ...............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=RMSprop, score=0.586, total=   7.3s\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:  6.2min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=RMSprop ...............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=RMSprop, score=0.593, total=   7.5s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  6.3min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=Adagrad ...............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=Adagrad, score=0.536, total=   6.7s\n",
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:  6.4min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=Adagrad ...............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=Adagrad, score=0.520, total=   7.2s\n",
      "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:  6.5min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=Adadelta ..............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:  6.6min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=Adadelta ..............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:  6.6min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=Adam ..................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=Adam, score=0.586, total=  10.9s\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=Adam ..................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=Adam, score=0.573, total=   6.6s\n",
      "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:  6.9min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=Adamax ................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=Adamax, score=0.578, total=   6.8s\n",
      "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:  7.0min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=Adamax ................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=Adamax, score=0.581, total=   6.8s\n",
      "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:  7.1min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=Nadam .................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=Nadam, score=0.586, total=  11.1s\n",
      "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:  7.3min remaining:    0.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.1, optimizer=Nadam .................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.1, optimizer=Nadam, score=0.573, total=  13.1s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=SGD ...................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=SGD, score=0.535, total=   5.7s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=SGD ...................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=SGD, score=0.538, total=   5.9s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=RMSprop ...............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=RMSprop, score=0.587, total=   9.0s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=RMSprop ...............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=RMSprop, score=0.590, total=   9.1s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=Adagrad ...............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=Adagrad, score=0.529, total=   7.5s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=Adagrad ...............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=Adagrad, score=0.517, total=  10.3s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=Adadelta ..............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=Adadelta ..............\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=Adam ..................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=Adam, score=0.586, total=   6.6s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=Adam ..................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=Adam, score=0.573, total=   6.6s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=Adamax ................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=Adamax, score=0.582, total=   7.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=Adamax ................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=Adamax, score=0.586, total=   7.7s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=Nadam .................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=Nadam, score=0.585, total=  13.4s\n",
      "[CV] batch_size=5, epochs=5, lr=0.5, optimizer=Nadam .................\n",
      "[CV]  batch_size=5, epochs=5, lr=0.5, optimizer=Nadam, score=0.572, total=  10.7s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=SGD .................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=SGD, score=0.580, total=   9.1s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=SGD .................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=SGD, score=0.573, total=   9.4s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=RMSprop .............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=RMSprop, score=0.579, total=  13.1s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=RMSprop .............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=RMSprop, score=0.584, total=  15.8s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=Adagrad .............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=Adagrad, score=0.555, total=  10.4s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=Adagrad .............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=Adagrad, score=0.550, total=  10.6s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=Adadelta ............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=Adadelta ............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=Adam ................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=Adam, score=0.569, total=  11.8s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=Adam ................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=Adam, score=0.556, total=  12.1s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=Adamax ..............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=Adamax, score=0.587, total=  12.0s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=Adamax ..............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=Adamax, score=0.583, total=  15.2s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=Nadam ...............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=Nadam, score=0.569, total=  17.9s\n",
      "[CV] batch_size=5, epochs=10, lr=0.01, optimizer=Nadam ...............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.01, optimizer=Nadam, score=0.557, total=  17.8s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=SGD ..................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=SGD, score=0.565, total=  10.1s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=SGD ..................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=SGD, score=0.559, total=  10.2s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=RMSprop, score=0.578, total=  17.4s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=RMSprop, score=0.585, total=  12.4s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=Adagrad, score=0.550, total=  10.3s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=Adagrad, score=0.550, total=  11.3s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=Adadelta .............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=Adadelta, score=nan, total=   0.9s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=Adadelta .............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=Adam .................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=Adam, score=0.568, total=  10.8s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=Adam .................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=Adam, score=0.557, total=  16.1s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=Adamax ...............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=Adamax, score=0.588, total=  11.4s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=Adamax ...............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=Adamax, score=0.581, total=  11.3s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=Nadam ................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=Nadam, score=0.571, total=  17.5s\n",
      "[CV] batch_size=5, epochs=10, lr=0.1, optimizer=Nadam ................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.1, optimizer=Nadam, score=0.555, total=  19.4s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=SGD ..................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=SGD, score=0.543, total=  13.3s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=SGD ..................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=SGD, score=0.544, total=   9.2s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=RMSprop, score=0.579, total=  12.6s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=RMSprop, score=0.585, total=  12.5s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=Adagrad, score=0.553, total=  10.6s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=Adagrad, score=0.546, total=  11.3s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=Adadelta .............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=Adadelta .............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=Adam .................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=Adam, score=0.569, total=  14.2s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=Adam .................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=Adam, score=0.558, total=  11.3s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=Adamax ...............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=Adamax, score=0.591, total=  11.1s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=Adamax ...............\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=Adamax, score=0.585, total=  11.3s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=Nadam ................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=Nadam, score=0.570, total=  18.4s\n",
      "[CV] batch_size=5, epochs=10, lr=0.5, optimizer=Nadam ................\n",
      "[CV]  batch_size=5, epochs=10, lr=0.5, optimizer=Nadam, score=0.558, total=  20.8s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=SGD .................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=SGD, score=0.526, total=   3.3s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=SGD .................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=SGD, score=0.524, total=   3.5s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=RMSprop .............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=RMSprop, score=0.587, total=   4.7s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=RMSprop .............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=RMSprop, score=0.587, total=   5.2s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=Adagrad .............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=Adagrad, score=0.425, total=   3.8s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=Adagrad .............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=Adagrad, score=0.386, total=   5.9s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=Adadelta ............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=Adadelta ............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=Adam ................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=Adam, score=0.587, total=   3.4s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=Adam ................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=Adam, score=0.588, total=   3.6s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=Adamax ..............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=Adamax, score=0.558, total=   4.9s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=Adamax ..............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=Adamax, score=0.562, total=   4.9s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=Nadam ...............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=Nadam, score=0.586, total=   9.0s\n",
      "[CV] batch_size=20, epochs=2, lr=0.01, optimizer=Nadam ...............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.01, optimizer=Nadam, score=0.580, total=   4.0s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=SGD ..................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=SGD, score=0.575, total=   3.4s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=SGD ..................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=SGD, score=0.570, total=   3.8s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=RMSprop, score=0.583, total=   4.9s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=RMSprop, score=0.586, total=   7.4s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=Adagrad, score=0.426, total=   3.5s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=Adagrad, score=0.395, total=   3.5s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=Adadelta .............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=Adadelta .............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=Adam .................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=Adam, score=0.584, total=   3.5s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=Adam .................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=Adam, score=0.589, total=   5.2s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=Adamax ...............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=Adamax, score=0.569, total=   8.9s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=Adamax ...............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=Adamax, score=0.562, total=   3.5s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=Nadam ................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=Nadam, score=0.588, total=   3.8s\n",
      "[CV] batch_size=20, epochs=2, lr=0.1, optimizer=Nadam ................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.1, optimizer=Nadam, score=0.582, total=   3.7s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=SGD ..................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=SGD, score=0.571, total=   6.5s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=SGD ..................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=SGD, score=0.548, total=  17.4s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=RMSprop, score=0.579, total=   3.7s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=RMSprop, score=0.585, total=   3.5s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=Adagrad, score=0.415, total=   3.2s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=Adagrad, score=0.398, total=   9.1s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=Adadelta .............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=Adadelta, score=nan, total=   5.7s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=Adadelta .............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=Adam .................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=Adam, score=0.588, total=   5.4s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=Adam .................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=Adam, score=0.584, total=   8.0s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=Adamax ...............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=Adamax, score=0.563, total=   3.3s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=Adamax ...............\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=Adamax, score=0.560, total=   3.3s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=Nadam ................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=Nadam, score=0.581, total=  25.1s\n",
      "[CV] batch_size=20, epochs=2, lr=0.5, optimizer=Nadam ................\n",
      "[CV]  batch_size=20, epochs=2, lr=0.5, optimizer=Nadam, score=0.585, total=   7.1s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=SGD .................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=SGD, score=0.548, total=   8.7s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=SGD .................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=SGD, score=0.548, total=   5.2s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=RMSprop .............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=RMSprop, score=0.590, total=   5.9s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=RMSprop .............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=RMSprop, score=0.591, total=   8.2s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=Adagrad .............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=Adagrad, score=0.496, total=   7.8s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=Adagrad .............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=Adagrad, score=0.476, total=   5.9s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=Adadelta ............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=Adadelta, score=nan, total=   3.3s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=Adadelta ............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=Adam ................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=Adam, score=0.589, total=   5.4s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=Adam ................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=Adam, score=0.584, total=   5.5s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=Adamax ..............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=Adamax, score=0.578, total=   5.5s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=Adamax ..............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=Adamax, score=0.577, total=   8.4s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=Nadam ...............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=Nadam, score=0.590, total=   8.8s\n",
      "[CV] batch_size=20, epochs=5, lr=0.01, optimizer=Nadam ...............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.01, optimizer=Nadam, score=0.585, total=  10.8s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=SGD ..................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=SGD, score=0.581, total=   5.2s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=SGD ..................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=SGD, score=0.573, total=   5.2s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=RMSprop, score=0.589, total=   8.2s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=RMSprop, score=0.590, total=  14.4s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=Adagrad, score=0.489, total=   9.9s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=Adagrad ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=Adagrad, score=0.462, total=   5.3s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=Adadelta .............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=Adadelta .............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=Adam .................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=Adam, score=0.590, total=   5.5s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=Adam .................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=Adam, score=0.584, total=   7.9s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=Adamax ...............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=Adamax, score=0.581, total=  14.5s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=Adamax ...............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=Adamax, score=0.580, total=   9.7s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=Nadam ................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=Nadam, score=0.590, total=   6.5s\n",
      "[CV] batch_size=20, epochs=5, lr=0.1, optimizer=Nadam ................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.1, optimizer=Nadam, score=0.586, total=   6.6s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=SGD ..................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=SGD, score=0.564, total=   9.4s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=SGD ..................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=SGD, score=0.567, total=  14.4s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=RMSprop, score=0.592, total=  10.4s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=RMSprop, score=0.590, total=   5.8s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=Adagrad, score=0.496, total=   5.3s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=Adagrad, score=0.463, total=   9.6s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=Adadelta .............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=Adadelta, score=nan, total=   1.0s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=Adadelta .............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=Adam .................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=Adam, score=0.590, total=   9.7s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=Adam .................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=Adam, score=0.584, total=   6.4s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=Adamax ...............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=Adamax, score=0.578, total=   9.9s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=Adamax ...............\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=Adamax, score=0.578, total=   6.1s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=Nadam ................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=Nadam, score=0.591, total=   7.1s\n",
      "[CV] batch_size=20, epochs=5, lr=0.5, optimizer=Nadam ................\n",
      "[CV]  batch_size=20, epochs=5, lr=0.5, optimizer=Nadam, score=0.585, total=   7.8s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=SGD ................\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=SGD, score=0.570, total=   9.5s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=SGD ................\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=SGD, score=0.563, total=  11.6s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=RMSprop ............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=RMSprop, score=0.582, total=  10.1s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=RMSprop ............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=RMSprop, score=0.587, total=  10.0s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=Adagrad ............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=Adagrad, score=0.522, total=   9.1s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=Adagrad ............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=Adagrad, score=0.515, total=   9.8s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=Adadelta ...........\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=Adadelta, score=nan, total=   0.9s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=Adadelta ...........\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=Adam ...............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=Adam, score=0.586, total=  11.3s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=Adam ...............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=Adam, score=0.573, total=   9.2s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=Adamax .............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=Adamax, score=0.587, total=   9.2s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=Adamax .............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=Adamax, score=0.587, total=   9.4s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=Nadam ..............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=Nadam, score=0.584, total=  13.0s\n",
      "[CV] batch_size=20, epochs=10, lr=0.01, optimizer=Nadam ..............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.01, optimizer=Nadam, score=0.576, total=  14.5s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=SGD .................\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=SGD, score=0.573, total=   8.6s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=SGD .................\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=SGD, score=0.569, total=   8.7s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=RMSprop .............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=RMSprop, score=0.584, total=  11.5s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=RMSprop .............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=RMSprop, score=0.588, total=  10.1s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=Adagrad .............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=Adagrad, score=0.523, total=  10.8s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=Adagrad .............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=Adagrad, score=0.528, total=  25.2s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=Adadelta ............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=Adadelta ............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=Adam ................\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=Adam, score=0.586, total=   8.9s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=Adam ................\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=Adam, score=0.578, total=   9.0s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=Adamax ..............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=Adamax, score=0.589, total=   9.3s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=Adamax ..............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=Adamax, score=0.584, total=  14.0s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=Nadam ...............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=Nadam, score=0.586, total=  17.7s\n",
      "[CV] batch_size=20, epochs=10, lr=0.1, optimizer=Nadam ...............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.1, optimizer=Nadam, score=0.574, total=  11.1s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=SGD .................\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=SGD, score=0.563, total=   9.0s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=SGD .................\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=SGD, score=0.558, total=   9.0s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=RMSprop .............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=RMSprop, score=0.582, total=  13.8s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=RMSprop .............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=RMSprop, score=0.586, total=  23.1s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=Adagrad .............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=Adagrad, score=0.528, total=   8.7s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=Adagrad .............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=Adagrad, score=0.517, total=   8.9s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=Adadelta ............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=Adadelta ............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=Adam ................\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=Adam, score=0.586, total=  12.1s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=Adam ................\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=Adam, score=0.575, total=  18.8s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=Adamax ..............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=Adamax, score=0.589, total=  10.3s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=Adamax ..............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=Adamax, score=0.586, total=  14.2s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=Nadam ...............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=Nadam, score=0.585, total=  11.1s\n",
      "[CV] batch_size=20, epochs=10, lr=0.5, optimizer=Nadam ...............\n",
      "[CV]  batch_size=20, epochs=10, lr=0.5, optimizer=Nadam, score=0.576, total=  11.1s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=SGD .................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=SGD, score=0.477, total=   4.2s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=SGD .................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=SGD, score=0.465, total=   4.6s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=RMSprop .............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=RMSprop, score=0.577, total=   7.6s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=RMSprop .............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=RMSprop, score=0.582, total=   3.1s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=Adagrad .............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=Adagrad, score=0.357, total=   3.0s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=Adagrad .............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=Adagrad, score=0.347, total=   5.7s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=Adadelta ............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=Adadelta, score=nan, total=   0.9s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=Adadelta ............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=Adam ................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=Adam, score=0.582, total=  14.2s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=Adam ................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=Adam, score=0.580, total=   8.2s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=Adamax ..............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=Adamax, score=0.553, total=   3.2s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=Adamax ..............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=Adamax, score=0.548, total=   3.2s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=Nadam ...............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=Nadam, score=0.584, total=   3.6s\n",
      "[CV] batch_size=50, epochs=2, lr=0.01, optimizer=Nadam ...............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.01, optimizer=Nadam, score=0.580, total=   4.7s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=SGD ..................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=SGD, score=0.560, total=   8.4s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=SGD ..................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=SGD, score=0.560, total=   3.1s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=RMSprop, score=0.581, total=   3.1s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=RMSprop, score=0.583, total=   3.2s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=Adagrad, score=0.368, total=   5.3s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=Adagrad, score=0.349, total=   5.9s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=Adadelta .............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=Adadelta, score=nan, total=   0.9s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=Adadelta .............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=Adam .................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=Adam, score=0.580, total=   7.5s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=Adam .................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=Adam, score=0.584, total=   3.2s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=Adamax ...............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=Adamax, score=0.557, total=   3.3s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=Adamax ...............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=Adamax, score=0.555, total=   3.5s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=Nadam ................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=Nadam, score=0.582, total=   4.8s\n",
      "[CV] batch_size=50, epochs=2, lr=0.1, optimizer=Nadam ................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.1, optimizer=Nadam, score=0.580, total=   7.9s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=SGD ..................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=SGD, score=0.578, total=   3.1s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=SGD ..................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=SGD, score=0.561, total=   3.0s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=RMSprop, score=0.580, total=   3.1s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=RMSprop, score=0.581, total=   3.0s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=Adagrad, score=0.375, total=   7.6s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=Adagrad, score=0.348, total=  18.6s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=Adadelta .............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=Adadelta .............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=Adam .................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=Adam, score=0.579, total=   3.0s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=Adam .................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=Adam, score=0.581, total=   3.0s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=Adamax ...............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=Adamax, score=0.566, total=   2.9s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=Adamax ...............\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=Adamax, score=0.554, total=   5.0s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=Nadam ................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=Nadam, score=0.580, total=   8.0s\n",
      "[CV] batch_size=50, epochs=2, lr=0.5, optimizer=Nadam ................\n",
      "[CV]  batch_size=50, epochs=2, lr=0.5, optimizer=Nadam, score=0.581, total=   3.3s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=SGD .................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=SGD, score=0.522, total=   4.7s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=SGD .................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=SGD, score=0.525, total=   8.2s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=RMSprop .............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=RMSprop, score=0.586, total=   8.6s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=RMSprop .............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=RMSprop, score=0.590, total=  10.4s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=Adagrad .............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=Adagrad, score=0.440, total=   4.9s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=Adagrad .............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=Adagrad, score=0.416, total=   4.7s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=Adadelta ............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=Adadelta ............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=Adam ................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=Adam, score=0.589, total=   4.8s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=Adam ................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=Adam, score=0.587, total=   8.4s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=Adamax ..............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=Adamax, score=0.579, total=   8.0s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=Adamax ..............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=Adamax, score=0.577, total=  10.4s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=Nadam ...............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=Nadam, score=0.586, total=   5.4s\n",
      "[CV] batch_size=50, epochs=5, lr=0.01, optimizer=Nadam ...............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.01, optimizer=Nadam, score=0.586, total=   5.5s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=SGD ..................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=SGD, score=0.580, total=   4.8s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=SGD ..................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=SGD, score=0.572, total=   6.6s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=RMSprop, score=0.590, total=   9.4s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=RMSprop, score=0.589, total=   5.0s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=Adagrad, score=0.442, total=   4.8s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=Adagrad, score=0.399, total=   4.7s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=Adadelta .............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=Adadelta .............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=Adam .................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=Adam, score=0.588, total=   9.3s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=Adam .................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=Adam, score=0.585, total=  12.5s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=Adamax ...............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=Adamax, score=0.570, total=   9.3s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=Adamax ...............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=Adamax, score=0.577, total=   4.9s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=Nadam ................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=Nadam, score=0.588, total=   5.4s\n",
      "[CV] batch_size=50, epochs=5, lr=0.1, optimizer=Nadam ................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.1, optimizer=Nadam, score=0.588, total=   5.8s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=SGD ..................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=SGD, score=0.576, total=   9.2s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=SGD ..................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=SGD, score=0.573, total=   4.9s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=RMSprop, score=0.592, total=   5.2s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=RMSprop ..............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=RMSprop, score=0.586, total=   5.4s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=Adagrad, score=0.427, total=   6.1s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=Adagrad ..............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=Adagrad, score=0.422, total=   5.8s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=Adadelta .............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=Adadelta, score=nan, total=   0.9s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=Adadelta .............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=Adam .................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=Adam, score=0.587, total=   9.9s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=Adam .................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=Adam, score=0.585, total=   4.8s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=Adamax ...............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=Adamax, score=0.577, total=   4.8s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=Adamax ...............\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=Adamax, score=0.577, total=   7.4s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=Nadam ................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=Nadam, score=0.586, total=   8.3s\n",
      "[CV] batch_size=50, epochs=5, lr=0.5, optimizer=Nadam ................\n",
      "[CV]  batch_size=50, epochs=5, lr=0.5, optimizer=Nadam, score=0.585, total=  10.1s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=SGD ................\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=SGD, score=0.542, total=   7.4s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=SGD ................\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=SGD, score=0.546, total=   7.4s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=RMSprop ............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=RMSprop, score=0.587, total=  12.4s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=RMSprop ............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=RMSprop, score=0.581, total=  13.4s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=Adagrad ............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=Adagrad, score=0.490, total=  14.0s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=Adagrad ............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=Adagrad, score=0.471, total=   7.8s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=Adadelta ...........\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=Adadelta ...........\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=Adadelta, score=nan, total=   0.7s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=Adam ...............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=Adam, score=0.589, total=   7.8s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=Adam ...............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=Adam, score=0.582, total=   8.0s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=Adamax .............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=Adamax, score=0.584, total=   8.4s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=Adamax .............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=Adamax, score=0.585, total=   9.9s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=Nadam ..............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=Nadam, score=0.587, total=  13.4s\n",
      "[CV] batch_size=50, epochs=10, lr=0.01, optimizer=Nadam ..............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.01, optimizer=Nadam, score=0.581, total=   8.7s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=SGD .................\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=SGD, score=0.580, total=   7.4s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=SGD .................\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=SGD, score=0.572, total=   7.7s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=RMSprop .............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=RMSprop, score=0.589, total=  10.7s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=RMSprop .............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=RMSprop, score=0.582, total=  15.5s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=Adagrad .............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=Adagrad, score=0.495, total=   8.0s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=Adagrad .............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=Adagrad, score=0.472, total=   7.9s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=Adadelta ............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=Adadelta ............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=Adam ................\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=Adam, score=0.588, total=   7.7s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=Adam ................\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=Adam, score=0.581, total=  13.4s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=Adamax ..............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=Adamax, score=0.583, total=  23.0s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=Adamax ..............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=Adamax, score=0.582, total=  13.1s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=Nadam ...............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=Nadam, score=0.587, total=   8.6s\n",
      "[CV] batch_size=50, epochs=10, lr=0.1, optimizer=Nadam ...............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.1, optimizer=Nadam, score=0.581, total=   8.6s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=SGD .................\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=SGD, score=0.568, total=  11.8s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=SGD .................\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=SGD, score=0.565, total=  21.1s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=RMSprop .............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=RMSprop, score=0.587, total=   8.4s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=RMSprop .............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=RMSprop, score=0.583, total=   8.2s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=Adagrad .............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=Adagrad, score=0.489, total=   7.6s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=Adagrad .............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=Adagrad, score=0.470, total=  10.3s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=Adadelta ............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=Adadelta, score=nan, total=   1.3s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=Adadelta ............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=Adadelta, score=nan, total=   0.8s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=Adam ................\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=Adam, score=0.586, total=  17.2s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=Adam ................\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=Adam, score=0.582, total=  10.9s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=Adamax ..............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=Adamax, score=0.586, total=   7.8s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=Adamax ..............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=Adamax, score=0.580, total=   7.7s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=Nadam ...............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=Nadam, score=0.588, total=  11.0s\n",
      "[CV] batch_size=50, epochs=10, lr=0.5, optimizer=Nadam ...............\n",
      "[CV]  batch_size=50, epochs=10, lr=0.5, optimizer=Nadam, score=0.580, total=  15.3s\n",
      "[Parallel(n_jobs=1)]: Done 378 out of 378 | elapsed: 47.8min finished\n",
      "Best: 0.590900 using {'batch_size': 20, 'epochs': 5, 'lr': 0.5, 'optimizer': 'RMSprop'}\n",
      "0.560600 (0.002200) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.01, 'optimizer': 'SGD'}\n",
      "0.584600 (0.000400) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.01, 'optimizer': 'RMSprop'}\n",
      "0.474100 (0.010500) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adadelta'}\n",
      "0.584900 (0.000900) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adam'}\n",
      "0.564900 (0.002100) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adamax'}\n",
      "0.583300 (0.005500) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Nadam'}\n",
      "0.565300 (0.007300) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.1, 'optimizer': 'SGD'}\n",
      "0.585000 (0.001200) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.1, 'optimizer': 'RMSprop'}\n",
      "0.485000 (0.013800) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adadelta'}\n",
      "0.584500 (0.000500) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adam'}\n",
      "0.565400 (0.001000) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adamax'}\n",
      "0.585200 (0.001000) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Nadam'}\n",
      "0.510600 (0.032000) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.5, 'optimizer': 'SGD'}\n",
      "0.582900 (0.000700) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.5, 'optimizer': 'RMSprop'}\n",
      "0.478400 (0.011400) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adadelta'}\n",
      "0.586300 (0.000300) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adam'}\n",
      "0.566600 (0.002400) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adamax'}\n",
      "0.584600 (0.000600) with: {'batch_size': 5, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Nadam'}\n",
      "0.574900 (0.000900) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.01, 'optimizer': 'SGD'}\n",
      "0.587800 (0.002200) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.01, 'optimizer': 'RMSprop'}\n",
      "0.524300 (0.011700) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adadelta'}\n",
      "0.577200 (0.007000) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adam'}\n",
      "0.579500 (0.001100) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adamax'}\n",
      "0.580100 (0.005700) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Nadam'}\n",
      "0.567800 (0.000800) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.1, 'optimizer': 'SGD'}\n",
      "0.589200 (0.003600) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.1, 'optimizer': 'RMSprop'}\n",
      "0.527800 (0.008000) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adadelta'}\n",
      "0.579100 (0.006500) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adam'}\n",
      "0.579800 (0.001400) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adamax'}\n",
      "0.579600 (0.006800) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Nadam'}\n",
      "0.536600 (0.001200) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.5, 'optimizer': 'SGD'}\n",
      "0.588300 (0.001700) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.5, 'optimizer': 'RMSprop'}\n",
      "0.523100 (0.006300) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adadelta'}\n",
      "0.579800 (0.006600) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adam'}\n",
      "0.583800 (0.001800) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adamax'}\n",
      "0.578600 (0.006400) with: {'batch_size': 5, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Nadam'}\n",
      "0.576600 (0.003400) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.01, 'optimizer': 'SGD'}\n",
      "0.581400 (0.002800) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.01, 'optimizer': 'RMSprop'}\n",
      "0.552300 (0.002500) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adadelta'}\n",
      "0.562600 (0.006400) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adam'}\n",
      "0.585100 (0.001900) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adamax'}\n",
      "0.563000 (0.006200) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Nadam'}\n",
      "0.562300 (0.002900) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.1, 'optimizer': 'SGD'}\n",
      "0.581500 (0.003100) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.1, 'optimizer': 'RMSprop'}\n",
      "0.550100 (0.000300) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adadelta'}\n",
      "0.562600 (0.005400) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adam'}\n",
      "0.584700 (0.003500) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adamax'}\n",
      "0.563200 (0.007800) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Nadam'}\n",
      "0.543400 (0.000600) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.5, 'optimizer': 'SGD'}\n",
      "0.581800 (0.003200) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.5, 'optimizer': 'RMSprop'}\n",
      "0.549900 (0.003500) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adadelta'}\n",
      "0.563700 (0.005700) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adam'}\n",
      "0.588000 (0.003200) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adamax'}\n",
      "0.563600 (0.006000) with: {'batch_size': 5, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Nadam'}\n",
      "0.524900 (0.000700) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.01, 'optimizer': 'SGD'}\n",
      "0.586900 (0.000300) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.01, 'optimizer': 'RMSprop'}\n",
      "0.405800 (0.019600) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adadelta'}\n",
      "0.587700 (0.000300) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adam'}\n",
      "0.559800 (0.002200) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adamax'}\n",
      "0.583000 (0.003000) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Nadam'}\n",
      "0.572500 (0.002900) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.1, 'optimizer': 'SGD'}\n",
      "0.584400 (0.001200) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.1, 'optimizer': 'RMSprop'}\n",
      "0.410700 (0.015700) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adadelta'}\n",
      "0.586300 (0.002300) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adam'}\n",
      "0.565200 (0.003600) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adamax'}\n",
      "0.585100 (0.003300) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Nadam'}\n",
      "0.559400 (0.011400) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.5, 'optimizer': 'SGD'}\n",
      "0.582400 (0.003000) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.5, 'optimizer': 'RMSprop'}\n",
      "0.406300 (0.008700) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adadelta'}\n",
      "0.585700 (0.001900) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adam'}\n",
      "0.561700 (0.001300) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adamax'}\n",
      "0.583200 (0.002200) with: {'batch_size': 20, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Nadam'}\n",
      "0.547900 (0.000100) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.01, 'optimizer': 'SGD'}\n",
      "0.590600 (0.000800) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.01, 'optimizer': 'RMSprop'}\n",
      "0.485900 (0.010300) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adadelta'}\n",
      "0.586300 (0.002500) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adam'}\n",
      "0.577600 (0.000400) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adamax'}\n",
      "0.587200 (0.002600) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Nadam'}\n",
      "0.577300 (0.003900) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.1, 'optimizer': 'SGD'}\n",
      "0.589600 (0.000600) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.1, 'optimizer': 'RMSprop'}\n",
      "0.475300 (0.013700) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adadelta'}\n",
      "0.587400 (0.003000) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adam'}\n",
      "0.580500 (0.000700) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adamax'}\n",
      "0.587700 (0.002100) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Nadam'}\n",
      "0.565600 (0.001400) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.5, 'optimizer': 'SGD'}\n",
      "0.590900 (0.000900) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.5, 'optimizer': 'RMSprop'}\n",
      "0.479600 (0.016200) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adadelta'}\n",
      "0.586800 (0.002800) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adam'}\n",
      "0.578200 (0.000200) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adamax'}\n",
      "0.588200 (0.003200) with: {'batch_size': 20, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Nadam'}\n",
      "0.566300 (0.003500) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.01, 'optimizer': 'SGD'}\n",
      "0.584300 (0.002300) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.01, 'optimizer': 'RMSprop'}\n",
      "0.518500 (0.003100) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adadelta'}\n",
      "0.579100 (0.006500) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adam'}\n",
      "0.587100 (0.000100) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adamax'}\n",
      "0.579900 (0.003900) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Nadam'}\n",
      "0.570700 (0.001900) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.1, 'optimizer': 'SGD'}\n",
      "0.585700 (0.001900) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.1, 'optimizer': 'RMSprop'}\n",
      "0.525500 (0.002300) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adadelta'}\n",
      "0.582300 (0.003900) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adam'}\n",
      "0.586300 (0.002500) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adamax'}\n",
      "0.580000 (0.006000) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Nadam'}\n",
      "0.560600 (0.002600) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.5, 'optimizer': 'SGD'}\n",
      "0.584200 (0.002200) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.5, 'optimizer': 'RMSprop'}\n",
      "0.522200 (0.005600) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adadelta'}\n",
      "0.580200 (0.005600) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adam'}\n",
      "0.587400 (0.001200) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adamax'}\n",
      "0.580700 (0.004700) with: {'batch_size': 20, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Nadam'}\n",
      "0.470800 (0.006000) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.01, 'optimizer': 'SGD'}\n",
      "0.579800 (0.002600) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.01, 'optimizer': 'RMSprop'}\n",
      "0.351900 (0.005100) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adadelta'}\n",
      "0.580900 (0.001300) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adam'}\n",
      "0.550600 (0.002600) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Adamax'}\n",
      "0.581900 (0.001900) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.01, 'optimizer': 'Nadam'}\n",
      "0.559800 (0.000000) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.1, 'optimizer': 'SGD'}\n",
      "0.581900 (0.001300) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.1, 'optimizer': 'RMSprop'}\n",
      "0.358900 (0.009500) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adadelta'}\n",
      "0.581900 (0.001900) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adam'}\n",
      "0.556000 (0.001000) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Adamax'}\n",
      "0.581300 (0.000900) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.1, 'optimizer': 'Nadam'}\n",
      "0.569900 (0.008500) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.5, 'optimizer': 'SGD'}\n",
      "0.580500 (0.000300) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.5, 'optimizer': 'RMSprop'}\n",
      "0.361700 (0.013700) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adadelta'}\n",
      "0.580100 (0.000900) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adam'}\n",
      "0.559900 (0.005700) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Adamax'}\n",
      "0.580600 (0.000200) with: {'batch_size': 50, 'epochs': 2, 'lr': 0.5, 'optimizer': 'Nadam'}\n",
      "0.523500 (0.001100) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.01, 'optimizer': 'SGD'}\n",
      "0.588200 (0.002200) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.01, 'optimizer': 'RMSprop'}\n",
      "0.428000 (0.012200) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adadelta'}\n",
      "0.588000 (0.001200) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adam'}\n",
      "0.578000 (0.000800) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Adamax'}\n",
      "0.585800 (0.000200) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.01, 'optimizer': 'Nadam'}\n",
      "0.576000 (0.003600) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.1, 'optimizer': 'SGD'}\n",
      "0.589300 (0.000700) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.1, 'optimizer': 'RMSprop'}\n",
      "0.420700 (0.021700) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adadelta'}\n",
      "0.586400 (0.001200) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adam'}\n",
      "0.573300 (0.003500) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Adamax'}\n",
      "0.588200 (0.000200) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.1, 'optimizer': 'Nadam'}\n",
      "0.574500 (0.001900) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.5, 'optimizer': 'SGD'}\n",
      "0.589100 (0.003300) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.5, 'optimizer': 'RMSprop'}\n",
      "0.424200 (0.002400) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adadelta'}\n",
      "0.586000 (0.000800) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adam'}\n",
      "0.577000 (0.000200) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Adamax'}\n",
      "0.585600 (0.000400) with: {'batch_size': 50, 'epochs': 5, 'lr': 0.5, 'optimizer': 'Nadam'}\n",
      "0.543800 (0.001800) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.01, 'optimizer': 'SGD'}\n",
      "0.583700 (0.003100) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.01, 'optimizer': 'RMSprop'}\n",
      "0.480700 (0.009500) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adadelta'}\n",
      "0.585900 (0.003500) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adam'}\n",
      "0.584600 (0.000400) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Adamax'}\n",
      "0.584000 (0.003000) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.01, 'optimizer': 'Nadam'}\n",
      "0.576000 (0.004000) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.1, 'optimizer': 'SGD'}\n",
      "0.585800 (0.003600) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.1, 'optimizer': 'RMSprop'}\n",
      "0.483700 (0.011700) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adadelta'}\n",
      "0.584400 (0.003800) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adam'}\n",
      "0.582400 (0.000400) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Adamax'}\n",
      "0.584100 (0.002900) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.1, 'optimizer': 'Nadam'}\n",
      "0.566200 (0.001400) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.5, 'optimizer': 'SGD'}\n",
      "0.585000 (0.001800) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.5, 'optimizer': 'RMSprop'}\n",
      "0.479400 (0.009600) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adagrad'}\n",
      "nan (nan) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adadelta'}\n",
      "0.584400 (0.002000) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adam'}\n",
      "0.583000 (0.003400) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Adamax'}\n",
      "0.584100 (0.004100) with: {'batch_size': 50, 'epochs': 10, 'lr': 0.5, 'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer='SGD', lr = 0.1):\n",
    "    model = build_classifier(input_size=len(feats_dict), output_size=num_classes,optimizer=optimizer, learning_rate=lr)\n",
    "    return model\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "#create the model with the best epoch and batch size found in last step\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=5, verbose=0)\n",
    "\n",
    "# difine grid search parameter \n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'\n",
    "            ]\n",
    "lr = [0.01,0.1, 0.5]\n",
    "batch_size = [5, 20,50]\n",
    "epochs = [2, 5, 10]\n",
    "param_grid = dict(optimizer=optimizer, \n",
    "                  lr=lr,\n",
    "                  batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,verbose=70,cv=2)\n",
    "grid_result = grid.fit(train_feats_matrix, train_label_matrix,)\n",
    "\n",
    "# grid searching result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The best SLP model is\n",
    "### 'batch_size': 20, 'epochs': 5, 'lr': 0.5, 'optimizer': 'RMSprop'\n",
    "### The accuracy is 0.5909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
